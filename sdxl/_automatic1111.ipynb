{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import shutil\n",
    "import requests\n",
    "import subprocess\n",
    "from urllib.parse import urlparse, unquote\n",
    "from IPython.utils import capture\n",
    "from IPython.display import clear_output, display, HTML\n",
    "\n",
    "a2 = \"--console-log-level=error -c -x 16 -s 16 -k 1M\"\n",
    "w = binascii.a2b_uu(\"%=V5B=6D`\").decode('utf-8')\n",
    "sd = binascii.a2b_uu(\"04W1A8FQE+61I9F9U<VEO;@``\").decode('utf-8')\n",
    "sdw = binascii.a2b_uu(\"6<W1A8FQE+61I9F9U<VEO;BUW96)U:0``\").decode('utf-8')\n",
    "sai = binascii.a2b_uu(\"=<W1A8FQE+61I9F9U<VEO;BUS=&%B:6QI='DM86D`\").decode('utf-8')\n",
    "\n",
    "# 忽略警告 ignore warnings\n",
    "import warnings\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"                    # 3：只显示ERROR和FATAL级别的日志消息，忽略所有其他级别的消息。\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)     #这是一个警告过滤器，用于忽略UserWarning类别的警告。\n",
    "!git config --global advice.detachedHead false              #禁用GIT在分离头状态（detached HEAD）下显示建议消息的功能\n",
    "!sed -i 's@text = _formatwarnmsg(msg)@text =\\\"\\\"@g' /usr/lib/python3.10/warnings.py\n",
    "\n",
    "#检查是否使用GPU\n",
    "def check_gpu():\n",
    "    import tensorflow as tf\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    if len(physical_devices) > 0:\n",
    "        print(\"\\r\\033[96m GPU is available\", flush=True)\n",
    "    else:\n",
    "        print(\"\\r\\033[91m 没有使用GPU,请在代码执行程序-更改运行时类型-设置为GPU!\", flush=True)\n",
    "        display(HTML(\"<img src='https://i.ibb.co/xfb7pB7/check-gpu.png' width='560px'/>\"))\n",
    "        from google.colab import runtime\n",
    "        runtime.unassign()        \n",
    "check_gpu()\n",
    "\n",
    "#运行代码时,打印错误信息\n",
    "def run_code(code):\n",
    "    try:\n",
    "        output = subprocess.check_output(code, stderr=subprocess.STDOUT, shell=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"run code '{e.cmd}' failed with error:\")\n",
    "        print(e.output.decode())\n",
    "\n",
    "#下载自定义模型     #@param {type:\"string\"}\n",
    "def download_model(xiazai_link,xiazai_path):\n",
    "    urls = [url.strip() for url in re.split(r',|，', xiazai_link)]\n",
    "    \n",
    "    for url in urls:\n",
    "        response = requests.get(url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            content_disposition = response.headers.get('content-disposition')\n",
    "            if content_disposition:\n",
    "                file_name = unquote(content_disposition.split('filename=')[1])\n",
    "            else:\n",
    "                file_name = unquote(url.split(\"/\")[-1])\n",
    "            \n",
    "            filename = re.sub(r'[\";]','', file_name)\n",
    "            file_path = os.path.join(xiazai_path, file_name)\n",
    "\n",
    "            if not os.path.exists(file_path):\n",
    "                print(file_name, \",正在下载...\")\n",
    "                !aria2c {a2} {url} -o {file_name}\n",
    "                print(file_name,\",下载成功!\")\n",
    "            else:\n",
    "                print(file_name,\",文件已存在!\" )\n",
    "        else:\n",
    "            print(\"下载链接错误:\", url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#链接Google云盘\n",
    "if sd_path == \"drive\" or use_drive:\n",
    "    if not os.path.exists('/content/drive'):\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        print('Google Drive 已挂载成功！')\n",
    "\n",
    "%cd {sd_root}\n",
    "print('\\r\\033[97m 正在克隆或更新项目...', flush=True)\n",
    "if os.path.exists(sd_dir) and update_sd and sd_versions == \"Automatic1111-latest\":\n",
    "    !git -C {sd_dir} reset --hard && git -C {sd_dir} checkout master && sleep 1 && rm {sd_dir}/webui.sh && git -C {sd_dir} pull\n",
    "    print('项目更新完成！')\n",
    "else:\n",
    "    if sd_versions == \"Automatic1111-latest\":\n",
    "        run_code(f\"git clone -q --branch master https://github.com/AUTOMATIC1111/{sdw}\")\n",
    "    elif sd_versions == \"Automatic1111-v1.5.2\":\n",
    "        run_code(f\"git clone -q --branch v1.5.2 https://github.com/AUTOMATIC1111/{sdw}\")\n",
    "    print('项目克隆完成！')\n",
    "\n",
    "print('\\r\\033[97m 正在安装SD运行环境...', flush=True)\n",
    "\n",
    "run_code('apt-get -y update -qq')\n",
    "run_code('apt-get -y install -qq aria2')\n",
    "\n",
    "run_code(\"wget https://huggingface.co/Vanwise/sd-colab/resolve/main/libtcmalloc_minimal.so.4 -O /content/libtcmalloc_minimal.so.4\")\n",
    "os.environ['LD_PRELOAD'] = '/content/libtcmalloc_minimal.so.4'\n",
    "\n",
    "if sd_versions == \"Automatic1111-latest\":\n",
    "    with capture.capture_output() as cap:\n",
    "        os.chdir('/content/')\n",
    "        run_code(\"wget -q -i https://raw.githubusercontent.com/Van-wise/fast-sd/main/Dependencies/A1111.txt\")\n",
    "        os.system(\"dpkg -i *.deb\")\n",
    "        run_code('tar -C /content/ --zstd -xf sd_mrep.tar.zst')\n",
    "        run_code('tar -C / --zstd -xf gcolabdeps.tar.zst')\n",
    "        run_code('rm *.deb | rm *.zst | rm *.txt')\n",
    "        run_code(f'mv -n /content/sd/stablediffusion/* {sd_dir}/repositories/{sai} && rm -rf /content/sd')\n",
    "elif sd_versions == \"Automatic1111-v1.5.2\": \n",
    "    with capture.capture_output() as cap:\n",
    "        run_code(\"pip install -q torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2+cu118 torchtext==0.15.2 torchdata==0.6.1 --extra-index-url https://download.pytorch.org/whl/cu118 -U\")\n",
    "        run_code(\"pip install -q xformers==0.0.20 triton==2.0.0 gradio_client==0.2.7 -U\")\n",
    "        run_code(\"pip install --prefer-binary https://huggingface.co/Vanwise/sd-colab/resolve/main/CLIP.zip\")\n",
    "        run_code(\"pip install --prefer-binary https://huggingface.co/Vanwise/sd-colab/resolve/main/open_clip.zip\")\n",
    "        run_code(\"wget https://huggingface.co/Vanwise/sd-colab/resolve/main/repositories.zip\")\n",
    "        run_code(\"unzip -q repositories.zip -d /root/main/repositories\")\n",
    "        run_code(\"pip install -r /root/main/requirements_versions.txt\")\n",
    "\n",
    "run_code('apt --fix-broken install')\n",
    "run_code('pip install -qq pycloudflared ngrok tntn')\n",
    "run_code('pip install -qq translators chardet openai boto3 aliyun-python-sdk-core aliyun-python-sdk-alimt python-dotenv pyfunctional')\n",
    "\n",
    "print('运行环境，安装成功!')\n",
    "\n",
    "os.makedirs(f\"/content/{sd_root}/cache\", exist_ok=True)\n",
    "os.environ['TRANSFORMERS_CACHE'] = f\"/content/{sd_root}/cache\"\n",
    "os.environ['TORCH_HOME'] = f\"/content/{sd_root}/cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#链接 ckpt\n",
    "if ckpt_to_colab or sd_path == \"colab\":\n",
    "    ckpt_dir = f\"/root/{sd_name}/models/{sd}\"\n",
    "else:\n",
    "    ckpt_dir = f\"/content/drive/MyDrive/colab/models/{sd}\"\n",
    "\n",
    "print('\\r\\033[97m 正在下载主模型...', flush=True)\n",
    "if ckpt1 == 'SDXL_base':\n",
    "    if not os.path.exists(f'{ckpt_dir}/sd_xl_base_1.0_0.9vae.safetensors'):\n",
    "        !aria2c $a2 https://huggingface.co/ckpt/sd_xl_base_1.0/resolve/main/sd_xl_base_1.0_0.9vae.safetensors -d {ckpt_dir} -o sd_xl_base_1.0_0.9vae.safetensors\n",
    "elif ckpt1 == 'RunDiffusionXL':\n",
    "    if not os.path.exists(f'{ckpt_dir}/rundiffusionXL_beta.safetensors'):\n",
    "        !aria2c $a2 https://huggingface.co/ckpt/rundiffusion-xl/resolve/main/rundiffusionXL_beta.safetensors -d {ckpt_dir} -o rundiffusionXL_beta.safetensors\n",
    "elif ckpt1 == 'JuggernautXL':\n",
    "    if not os.path.exists(f'{ckpt_dir}/juggernautXL_version1.safetensors'):\n",
    "        !aria2c $a2 https://huggingface.co/ckpt/juggernaut-xl/resolve/main/juggernautXL_version1.safetensors -d {ckpt_dir} -o juggernautXL_version1.safetensors\n",
    "elif ckpt1 == '\\u81EA\\u5B9A\\u4E49':\n",
    "        !aria2c $a2 {ckpt1_downlink} -d {ckpt_dir}\n",
    "\n",
    "if ckpt2 == 'SDXL_refiner':\n",
    "    if not os.path.exists(f'{ckpt_dir}/sd_xl_refiner_1.0.safetensors'):\n",
    "        !aria2c $a2 https://huggingface.co/ckpt/sd_xl_refiner_1.0/resolve/main/sd_xl_refiner_1.0_0.9vae.safetensors -d {ckpt_dir} -o sd_xl_refiner_1.0.safetensors\n",
    "elif ckpt2 == 'ChilloutMix':\n",
    "        !aria2c $a2 https://huggingface.co/ckpt/chilloutmix/resolve/main/chilloutmix_NiPrunedFp32Fix.safetensors -d {ckpt_dir} -o chilloutmix_NiPrunedFp32Fix.safetensors\n",
    "elif ckpt2 == 'Counterfeit':\n",
    "        !aria2c $a2 https://huggingface.co/gsdf/Counterfeit-V3.0/resolve/main/Counterfeit-V3.0_fp32.safetensors -d {ckpt_dir} -o Counterfeit-V3.0_fp32.safetensors\n",
    "        \n",
    "ckpt_custom = \"https://civitai.com/models/25694/epicrealism\\uFF0Chttps://civitai.com/api/download/models/161185\"\n",
    "\n",
    "if ckpt_downlink:\n",
    "    def download_model(ckpt_downlink,ckpt_dir)   \n",
    "\n",
    "#链接 lora\n",
    "if lora_to_colab or sd_path == \"colab\":\n",
    "    lora_dir = f\"/content/{sd_name}/models/Lora\"\n",
    "else:\n",
    "    lora_dir = f\"/content/drive/MyDrive/colab/models/Lora\"\n",
    "\n",
    "print('\\r\\033[97m 正在下载loras模型...', flush=True)\n",
    "if lora1 == 'detail-tweaker':\n",
    "    if not os.path.exists(f'{lora_dir}/add_detail.safetensors'):\n",
    "        !aria2c $a2 https://huggingface.co/Vanwise/sd-models/resolve/main/lora/add_detail.safetensors -d {lora_dir} -o add_detail.safetensors\n",
    "elif lora1 == 'shojovibe_v11':\n",
    "    if not os.path.exists(f'{lora_dir}/shojovibe_v11.safetensors'):\n",
    "        !aria2c $a2 https://huggingface.co/Vanwise/sd-models/resolve/main/lora/shojovibe_v11.safetensors -d {lora_dir} -o shojovibe_v11.safetensors\n",
    "\n",
    "if lora_downlink:\n",
    "    def download_model(lora_downlink,lora_dir)   \n",
    "\n",
    "#链接 Lycoris\n",
    "lyco_dir = f\"{sd_dir}/models/Lycoris\"\n",
    "print('\\r\\033[97m 正在下载lycoris模型...', flush=True)\n",
    "if lyco1 == 'Neg4All':\n",
    "    if not os.path.exists(f'{lyco_dir}/neg4all_bdsqlsz_V3.5.safetensors'):\n",
    "        !aria2c $a2 https://huggingface.co/Vanwise/sd-models/resolve/main/lycoris/neg4all_bdsqlsz_V3.5.safetensors -d {lora_dir} -o neg4all_bdsqlsz_V3.5.safetensors\n",
    "elif lyco1 == 'Neg4All_XL':\n",
    "    if not os.path.exists(f'{lyco_dir}/neg4all_bdsqlsz_xl_V7.safetensors'):\n",
    "        !aria2c $a2 https://huggingface.co/Vanwise/sd-models/resolve/main/lycoris/neg4all_bdsqlsz_xl_V7.safetensors -d {lora_dir} -o neg4all_bdsqlsz_xl_V7.safetensors \n",
    "elif lyco1 == 'EnvyBetterHands': \n",
    "    if not os.path.exists(f'{lyco_dir}/GoodHands-beta2.safetensors'):\n",
    "        !aria2c $a2 https://civitai.com/api/download/models/55199 -d {lora_dir} -o GoodHands-beta2.safetensors\n",
    "\n",
    "if lyco_downlink:\n",
    "    def download_model(lyco_downlink,lyco_dir)   \n",
    "\n",
    "# 链接 VAE\n",
    "vae_dir = f\"{sd_dir}/models/VAE\"\n",
    "print('\\r\\033[97m 正在下载vae模型...', flush=True)\n",
    "if vae1 == 'kl-f8-anime2':\n",
    "    if not os.path.exists(f'{vae_dir}/kl-f8-anime2.vae.pt'):\n",
    "        !aria2c $a2 https://huggingface.co/Norisuke193/kl-f8-anime2/resolve/main/kl-f8-anime2.vae.pt -d {vae_dir} -o kl-f8-anime2.vae.pt\n",
    "elif vae1 == 'vae-ft-mse-840000':\n",
    "    if not os.path.exists(f'{vae_dir}/vae-ft-mse-840000-ema-pruned.safetensors'):\n",
    "        !aria2c $a2 https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors -d {vae_dir} -o vae-ft-mse-840000-ema-pruned.safetensors\n",
    "\n",
    "if vae_downlink:\n",
    "    def download_model(vae_downlink,vae_dir)  \n",
    "\n",
    "# 链接 embeddings\n",
    "embeddings_dir = f\"{sd_dir}/models/embeddings\"\n",
    "print('\\r\\033[97m 正在下载embeddings模型...', flush=True)\n",
    "if  dl_negative:\n",
    "    !git clone https://huggingface.co/Vanwise/negative/resolve/main/negative.zip\n",
    "    !unzip negative.zip -d {embeddings_dir}\n",
    "\n",
    "if embeddings_downlink:\n",
    "    def download_model(embeddings_downlink,embeddings_dir)  \n",
    "\n",
    "# 链接 hypernetwork\n",
    "hypernetworks_dir = f\"{sd_dir}/models/hypernetworks\" \n",
    "if hypernetworks_downlink:\n",
    "    def download_model(hypernetworks_downlink,hypernetworks_dir)  \n",
    "\n",
    "# 链接 scripts\n",
    "scripts_dir = f\"{sd_dir}/scripts\" \n",
    "# 链接 clip_vision\n",
    "clip_vision_dir = f\"{sd_dir}/models/clip_vision\"\n",
    "\n",
    "# 链接 ControlNet\n",
    "#@markdown ####<font color=\"#2b73af\"> 选择ControlNet：\n",
    "#@markdown #####<font color=\"#2c9678\">🔅☑把ControlNet模型下载到colab；☐把模型下载到云盘。\n",
    "cn_to_colab = True  #@param {type:\"boolean\"}\n",
    "\n",
    "if cn_to_colab or sd_path == \"colab\":\n",
    "    cn_dir = f\"/content/{sd_name}/models/controlnet\"\n",
    "else:\n",
    "    cn_dir = f\"/content/drive/MyDrive/{sd_name}/models/controlnet\"\n",
    "\n",
    "def download(url, model_dir):\n",
    "    filename = os.path.basename(urlparse(url).path)\n",
    "    pth = os.path.abspath(os.path.join(model_dir, filename))\n",
    "    if not os.path.exists(pth):\n",
    "        print('Downloading: ' + os.path.basename(url))\n",
    "        cmd = f\"aria2c $a2 -d {model_dir} -o {filename} {url}\"\n",
    "        subprocess.run(cmd, shell=True, check=True)\n",
    "    else:\n",
    "        print(f\"\u001b[1;32mThe model {filename} already exists\u001b[0m\")\n",
    "\n",
    "def cn_down():\n",
    "    if os.path.exists(\"CN_models.txt\"):\n",
    "        with open(\"CN_models.txt\", 'r') as f:\n",
    "            mdllnk = f.read().splitlines()\n",
    "    for lnk in mdllnk:\n",
    "        download(lnk, cn_dir)\n",
    "\n",
    "controlnet = \"\" # @param [\"\", \"SD15_base\", \"SD15_full\", \"SDXL_base\", \"SDXL_full\"]\n",
    "if controlnet == \"SD15_base\":\n",
    "    os.system(f\"curl -o CN_models.txt https://raw.githubusercontent.com/Van-wise/sd-colab/main/sdxl/cnDL_sd15base.txt\")\n",
    "    cn_down()\n",
    "elif controlnet == \"SD15_full\":\n",
    "    os.system(f\"curl -o CN_models.txt https://raw.githubusercontent.com/Van-wise/sd-colab/main/sdxl/cnDL_sd15full.txt\")\n",
    "    cn_down()\n",
    "elif controlnet == \"SDXL_base\":\n",
    "    os.system(f\"curl -o CN_models.txt https://raw.githubusercontent.com/Van-wise/sd-colab/main/sdxl/cnDL_sdxlbase.txt\")\n",
    "    cn_down()\n",
    "elif controlnet == \"SDXL_full\":\n",
    "    os.system(f\"curl -o CN_models.txt https://raw.githubusercontent.com/Van-wise/sd-colab/main/sdxl/cnDL_sdxlfull.txt\")\n",
    "    cn_down()\n",
    "else:    \n",
    "    print(\"不使用 ControlNet、或已使用快捷方式。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown ##<font color=\"#11659a\"> MOD!\n",
    "import pandas as pd\n",
    "from google.colab import files, drive\n",
    "#@markdown #####<font color=\"#2c9678\">🔅☑启用MOD功能；☐不使用MOD。\n",
    "enable_mod = False #@param {type:\"boolean\"} \n",
    "mod_name = \"mod.xlsx\"   #@param {type:\"string\"}\n",
    "mod_link = \"\"   #@param {type:\"string\"} \n",
    "\n",
    "def get_mod():\n",
    "    if mod_link:\n",
    "        filename = os.path.basename(mod_link)\n",
    "        if not filename.endswith('.xlsx'):\n",
    "            print(\"下载链接错误!\")\n",
    "            return None\n",
    "        !wget -q -T 10 {mod_link} -O {filename}\n",
    "        mod_file = f\"/content/{filename}\"\n",
    "        return mod_file \n",
    "\n",
    "    else:\n",
    "        while True:\n",
    "            try:\n",
    "                uploaded = files.upload()\n",
    "                if not uploaded:\n",
    "                    mod_file = None\n",
    "                    break\n",
    "                mod_file = os.path.join(os.getcwd(), list(uploaded.keys())[0])\n",
    "\n",
    "                if not mod_file.endswith('.xlsx'):\n",
    "                    raise ValueError(\"文件格式错误 .xlsx \")\n",
    "                break\n",
    "\n",
    "            except (ValueError, Exception) as e:\n",
    "                print(e)\n",
    "                print(\"请重新上传文件。\")\n",
    "\n",
    "        return mod_file\n",
    "\n",
    "def use_mod():\n",
    "    df = pd.read_excel(mod_file)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        file_type = row['类型']\n",
    "        file_name = row['名称']\n",
    "        download_link = row['下载地址']\n",
    "\n",
    "        if file_type == 'CKPT':\n",
    "            !aria2c $a2 {download_link} -d {ckpt_dir} -o {file_name}\n",
    "        elif file_type == 'Lora':\n",
    "            !aria2c $a2 {download_link} -d {lora_dir} -o {file_name}\n",
    "        elif file_type == 'VAE':\n",
    "            !aria2c $a2 {download_link} -d {vae_dir} -o {file_name}\n",
    "        elif file_type == 'Extensions':\n",
    "            repo_name = download_link.split('/')[-1]\n",
    "            !git clone {download_link} {sd_dir}/extensions/{repo_name}\n",
    "        elif file_type == 'Embeddings':\n",
    "            !aria2c $a2 {download_link} -d {embeddings_dir} -o {file_name}\n",
    "        elif file_type == 'Scripts':\n",
    "            !aria2c $a2 {download_link} -d {sd_dir}/scripts -o {file_name}\n",
    "        elif file_type == 'Controlnet':\n",
    "            !aria2c $a2 {download_link} -d {cn_dir} -o {file_name}\n",
    "        elif file_type == 'Comfyui_Nodes':\n",
    "            nodes_name = download_link.split('/')[-1]\n",
    "            !git clone {download_link} {sd_dir}/extensions/{nodes_name}\n",
    "\n",
    "if enable_mod:\n",
    "    mod_file = get_mod()\n",
    "    if mod_file:\n",
    "        use_mod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown---\n",
    "#@markdown ####<font color=\"#2b73af\"> 🌐☑使用云盘模型；☐不使用云盘模型。\n",
    "use_drive_model = False  #@param {type:\"boolean\"}\n",
    "#@markdown #####<font color=\"#2b73af\"> 两种方法：cp（从云盘复制到colab）；ln（添加云盘软链接到colab）\n",
    "content_way = \"\\u94FE\\u63A5ln\" #@param [\"\\u590D\\u5236cp\", \"\\u94FE\\u63A5ln\"]\n",
    "if use_drive and use_drive_model:\n",
    "    gckpt_dir = f\"/content/drive/MyDrive/{sd_name}/models/checkpoints\"\n",
    "    gLora_dir = f\"/content/drive/MyDrive/{sd_name}/models/Loras\"\n",
    "    gVAE_dir = f\"/content/drive/MyDrive/{sd_name}/models/vae\"\n",
    "    gembeddings_dir = f\"/content/drive/MyDrive/{sd_name}/embeddings\"\n",
    "    gcn_dir = f\"/content/drive/MyDrive/{sd_name}/extensions/models/controlnet\"\n",
    "    goutputs_dir = f\"/content/drive/MyDrive/{sd_name}/outputs\"\n",
    "    !mkdir -p {gLora_dir} {gVAE_dir} {gembeddings_dir} {gcn_dir} {goutputs_dir} {gckpt_dir}\n",
    "\n",
    "    if content_way == \"\\u590D\\u5236cp\":\n",
    "        !cp -r {gckpt_dir} {ckpt_dir}\n",
    "        !cp -r {gLora_dir} {Lora_dir}\n",
    "        !cp -r {gVAE_dir} {VAE_dir}\n",
    "        !cp -r {gembeddings_dir} {embeddings_dir}\n",
    "        !cp -r {gcn_dir} {cn_dir}\n",
    "    else:\n",
    "        !ln -sf {gckpt_dir} {ckpt_dir}\n",
    "        !ln -sf {gLora_dir} {Lora_dir}\n",
    "        !ln -sf {gVAE_dir} {VAE_dir}\n",
    "        !ln -sf {gembeddings_dir} {embeddings_dir}\n",
    "        !ln -sf {gcn_dir} {cn_dir}\n",
    "\n",
    "#@markdown---\n",
    "#@markdown ##<font color=\"#11659a\">▶️ Start Fooocus\n",
    "%cd {sd_dir}\n",
    "!python launch.py --share"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
