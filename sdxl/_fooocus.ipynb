{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import shutil\n",
    "import subprocess\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "#检查是否使用GPU\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "!git config --global advice.detachedHead false\n",
    "def check_gpu():\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    if len(physical_devices) > 0:\n",
    "        print(\"GPU is available\")\n",
    "    else:\n",
    "        sys.exit(\"\\n没有使用GPU，请在代码执行程序-更改运行时类型-设置为GPU！\\n如果不能使用GPU，建议更换账号！\")\n",
    "check_gpu()\n",
    "#运行代码时,打印错误信息\n",
    "def run_code(code):\n",
    "    try:\n",
    "        output = subprocess.check_output(code, stderr=subprocess.STDOUT, shell=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"run code '{e.cmd}' failed with error:\")\n",
    "        print(e.output.decode())\n",
    "\n",
    "#@markdown ##<font color=\"#11659a\"> 0️⃣模式选择：\n",
    "#@markdown #####<font color=\"#2b73af\"> colab是将Fooocus安装到colab；drive是将Fooocus安装到google云盘或启动云盘里的sd。 \n",
    "sd_path = \"colab\"  # @param [\"colab\", \"drive\"]\n",
    "if sd_path == \"colab\":\n",
    "    sd_dir = f\"/content/\"\n",
    "    print('将SD安装在colab磁盘中。')\n",
    "else:\n",
    "    sd_dir = f\"/content/drive/MyDrive/\"\n",
    "    print('将SD安装在google硬盘中。')\n",
    "\n",
    "#@markdown ####<font color=\"#11659a\"> 版本选择：\n",
    "#@markdown #####<font color=\"#2c9678\"> Fooocus是官方版；Fooocus-MRE是进阶版。 \n",
    "foocus_versions = \"Fooocus-MRE\" #@param [\"Fooocus\",\"Fooocus-MRE\"]\n",
    "if foocus_versions == \"Fooocus\":\n",
    "    sd_name = \"Fooocus\"\n",
    "else:\n",
    "    sd_name = \"Fooocus-MRE\"\n",
    "\n",
    "#@markdown #####<font color=\"#2c9678\">☑链接谷歌云盘；☐不使用谷歌云盘。\n",
    "use_drive = False  #@param {type:\"boolean\"}\n",
    "if sd_path == \"drive\" or use_drive:\n",
    "    if not os.path.exists('/content/drive'):\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        print('Google Drive 已挂载成功！')\n",
    "\n",
    "%cd {sd_dir}\n",
    "webui_dir = sd_dir + sd_name\n",
    "#@markdown #####<font color=\"#2c9678\">☑更新云盘Fooocus；☐不使用更新。\n",
    "update_sd = False  #@param {type:\"boolean\"}\n",
    "if os.path.exists(webui_dir) and update_sd:\n",
    "    !git -C {webui_dir} reset --hard && git -C {webui_dir} checkout master && sleep 1 && rm {webui_dir}/webui.sh && git -C {webui_dir} pull\n",
    "    print('Fooocus,更新完成！')\n",
    "else:\n",
    "    if foocus_versions == \"Fooocus\":\n",
    "        !git clone -q --branch master https://github.com/lllyasviel/Fooocus\n",
    "    else:\n",
    "        !git clone -q --branch moonride-main https://github.com/MoonRide303/Fooocus-MRE\n",
    "        !cp {webui_dir}/settings-no-refiner.json {webui_dir}/settings.json\n",
    "    print('Fooocus,克隆完成！')\n",
    "\n",
    "print('正在安装 Fooocus 运行环境!')\n",
    "run_code('apt-get -y update -qq')\n",
    "run_code('apt-get -y install -qq aria2 git')\n",
    "if foocus_versions == \"Fooocus\":\n",
    "    run_code('pip install torchsde==0.2.5 einops==0.4.1 transformers==4.30.2 safetensors==0.3.1 accelerate==0.21.0')\n",
    "    run_code('pip install pytorch_lightning==1.9.4 omegaconf==2.2.3 gradio==3.39.0 xformers==0.0.20 triton==2.0.0 pygit2==1.12.2')\n",
    "elif foocus_versions ==\"Fooocus-MRE\":\n",
    "    run_code('pip install torchsde==0.2.5 einops==0.4.1 transformers==4.30.2 safetensors==0.3.1 accelerate==0.21.0 aiohttp==3.8.5')\n",
    "    run_code('pip install pytorch_lightning==1.9.4 omegaconf==2.2.3 gradio==3.41.2 xformers==0.0.21 triton==2.0.0 pygit2==1.12.2 fastapi==0.94.0')   \n",
    "print('运行环境，安装成功!')\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ##<font color=\"#11659a\"> 1️⃣初始模型下载：\n",
    "#@markdown #####<font color=\"#2c9678\">🔅☑把主模型下载到colab；☐把模型下载到云盘。\n",
    "ckpt_to_colab = True  #@param {type:\"boolean\"}\n",
    "\n",
    "if ckpt_to_colab or sd_path == \"colab\":\n",
    "    ckpt_dir = f\"/content/{sd_name}/models/checkpoints\"\n",
    "else:\n",
    "    ckpt_dir = f\"/content/drive/MyDrive/{sd_name}/models/checkpoints\"\n",
    "\n",
    "#@markdown #####<font color=\"#20894d\"> ckpt_downlink 为直接下载链接，ckpt_filename 为模型文件名.\n",
    "ckpt1 = \"SDXL_base\" #@param [\"SDXL_base\",\"RunDiffusionXL\",\"JuggernautXL\",\"自定义\", \"\"]\n",
    "ckpt2 = \"\" #@param [\"SDXL1.0_refiner\",\"自定义\", \"\"]\n",
    "ckpt1_downlink = \"\" #@param {type:\"string\"}\n",
    "ckpt2_downlink = \"\" #@param {type:\"string\"}\n",
    "\n",
    "if ckpt1 == 'SDXL_base':\n",
    "    if not os.path.exists(f'{ckpt_dir}/sd_xl_base_1.0_0.9vae.safetensors'):\n",
    "        !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/sd_xl_base_1.0/resolve/main/sd_xl_base_1.0_0.9vae.safetensors -d {ckpt_dir} -o sd_xl_base_1.0_0.9vae.safetensors\n",
    "elif ckpt1 == 'RunDiffusionXL':\n",
    "    if not os.path.exists(f'{ckpt_dir}/rundiffusionXL_beta.safetensors'):\n",
    "        !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/rundiffusion-xl/resolve/main/rundiffusionXL_beta.safetensors -d {ckpt_dir} -o rundiffusionXL_beta.safetensors\n",
    "elif ckpt1 == 'JuggernautXL':\n",
    "    if not os.path.exists(f'{ckpt_dir}/juggernautXL_version1.safetensors'):\n",
    "        !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/juggernaut-xl/resolve/main/juggernautXL_version1.safetensors -d {ckpt_dir} -o juggernautXL_version1.safetensors\n",
    "elif ckpt1 == '\\u81EA\\u5B9A\\u4E49':\n",
    "        !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {ckpt1_downlink} -d {ckpt_dir}\n",
    "else:\n",
    "    print(\"暂时不下载主模型！\")\n",
    "\n",
    "if ckpt2 == 'SDXL_refiner':\n",
    "    if not os.path.exists(f'{ckpt_dir}/sd_xl_refiner_1.0.safetensors'):\n",
    "        !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/sd_xl_refiner_1.0/resolve/main/sd_xl_refiner_1.0_0.9vae.safetensors -d {ckpt_dir} -o sd_xl_refiner_1.0.safetensors\n",
    "elif ckpt2 == '\\u81EA\\u5B9A\\u4E49':\n",
    "        !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {ckpt2_downlink} -d {ckpt_dir}\n",
    "\n",
    "#@markdown #####<font color=\"#2c9678\">🔅☑把Lora模型下载到colab；☐把模型下载到云盘。\n",
    "lora_to_colab = True  #@param {type:\"boolean\"}\n",
    "\n",
    "if lora_to_colab or sd_path == \"colab\":\n",
    "    lora_dir = f\"/content/{sd_name}/models/loras\"\n",
    "else:\n",
    "    lora_dir = f\"/content/drive/MyDrive/{sd_name}/models/Lora\"\n",
    "\n",
    "#@markdown #####<font color=\"#20894d\"> lora_downlink 为直接下载链接，lora_filename 为模型文件名.\n",
    "lora1 = \"\" #@param [\"JuggerCineXL2\",\"自定义\", \"\"]\n",
    "lora_downlink = \"\" #@param {type:\"string\"}\n",
    "\n",
    "if lora1 == 'JuggerCineXL2':\n",
    "    if not os.path.exists(f'{lora_dir}/rundiffusionXL_beta.safetensors'):\n",
    "        !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/juggernaut-xl/resolve/main/JuggerCineXL2.safetensors -d {lora_dir} -o JuggerCineXL2.safetensors\n",
    "elif lora1 == '\\u81EA\\u5B9A\\u4E49':\n",
    "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {lora_downlink} -d {lora_dir}\n",
    "\n",
    "# 链接 VAE\n",
    "vae_dir = f\"{webui_dir}/models/embeddings\"\n",
    "\n",
    "# 链接 embeddings\n",
    "embeddings_dir = f\"{webui_dir}/models/embeddings\"\n",
    "\n",
    "# 链接 clip_vision\n",
    "clip_vision_dir = f\"{webui_dir}/models/clip_vision\"\n",
    "\n",
    "# 链接 hypernetwork\n",
    "hypernetworks_dir = f\"{webui_dir}/models/hypernetworks\" \n",
    "\n",
    "# 链接 scripts\n",
    "\n",
    "# 链接 ControlNet\n",
    "#@markdown ####<font color=\"#2b73af\"> 选择ControlNet：\n",
    "#@markdown #####<font color=\"#2c9678\">🔅☑把ControlNet模型下载到colab；☐把模型下载到云盘。\n",
    "cn_to_colab = True  #@param {type:\"boolean\"}\n",
    "\n",
    "if cn_to_colab or sd_path == \"colab\":\n",
    "    cn_dir = f\"/content/{sd_name}/models/controlnet\"\n",
    "else:\n",
    "    cn_dir = f\"/content/drive/MyDrive/{sd_name}/models/controlnet\"\n",
    "\n",
    "def download(url, model_dir):\n",
    "    filename = os.path.basename(urlparse(url).path)\n",
    "    pth = os.path.abspath(os.path.join(model_dir, filename))\n",
    "    if not os.path.exists(pth):\n",
    "        print('Downloading: ' + os.path.basename(url))\n",
    "        cmd = f\"aria2c --console-log-level=error -c -x 16 -s 16 -k 1M -d {model_dir} -o {filename} {url}\"\n",
    "        subprocess.run(cmd, shell=True, check=True)\n",
    "    else:\n",
    "        print(f\"\u001b[1;32mThe model {filename} already exists\u001b[0m\")\n",
    "\n",
    "def cn_down():\n",
    "    if os.path.exists(\"CN_models.txt\"):\n",
    "        with open(\"CN_models.txt\", 'r') as f:\n",
    "            mdllnk = f.read().splitlines()\n",
    "    for lnk in mdllnk:\n",
    "        download(lnk, cn_dir)\n",
    "\n",
    "controlnet = \"\" # @param [\"\", \"SD15_base\", \"SD15_full\", \"SDXL_base\", \"SDXL_full\"]\n",
    "if controlnet == \"SD15_base\":\n",
    "    os.system(f\"curl -o CN_models.txt https://raw.githubusercontent.com/Van-wise/sd-colab/main/sdxl/cnDL_sd15base.txt\")\n",
    "    cn_down()\n",
    "elif controlnet == \"SD15_full\":\n",
    "    os.system(f\"curl -o CN_models.txt https://raw.githubusercontent.com/Van-wise/sd-colab/main/sdxl/cnDL_sd15full.txt\")\n",
    "    cn_down()\n",
    "elif controlnet == \"SDXL_base\":\n",
    "    os.system(f\"curl -o CN_models.txt https://raw.githubusercontent.com/Van-wise/sd-colab/main/sdxl/cnDL_sdxlbase.txt\")\n",
    "    cn_down()\n",
    "elif controlnet == \"SDXL_full\":\n",
    "    os.system(f\"curl -o CN_models.txt https://raw.githubusercontent.com/Van-wise/sd-colab/main/sdxl/cnDL_sdxlfull.txt\")\n",
    "    cn_down()\n",
    "else:    \n",
    "    print(\"不使用 ControlNet、或已使用快捷方式。\")\n",
    "\n",
    "#@markdown ##<font color=\"#11659a\"> MOD!\n",
    "import pandas as pd\n",
    "from google.colab import files, drive\n",
    "#@markdown #####<font color=\"#2c9678\">🔅☑启用MOD功能；☐不使用MOD。\n",
    "enable_mod = False #@param {type:\"boolean\"} \n",
    "mod_name = \"mod.xlsx\"   #@param {type:\"string\"}\n",
    "mod_link = \"\"   #@param {type:\"string\"} \n",
    "\n",
    "def get_mod():\n",
    "    if mod_link:\n",
    "        filename = os.path.basename(mod_link)\n",
    "        if not filename.endswith('.xlsx'):\n",
    "            print(\"下载链接错误!\")\n",
    "            return None\n",
    "        !wget -q -T 10 {mod_link} -O {filename}\n",
    "        mod_file = f\"/content/{filename}\"\n",
    "        return mod_file \n",
    "\n",
    "    else:\n",
    "        while True:\n",
    "            try:\n",
    "                uploaded = files.upload()\n",
    "                if not uploaded:\n",
    "                    mod_file = None\n",
    "                    break\n",
    "                mod_file = os.path.join(os.getcwd(), list(uploaded.keys())[0])\n",
    "\n",
    "                if not mod_file.endswith('.xlsx'):\n",
    "                    raise ValueError(\"文件格式错误 .xlsx \")\n",
    "                break\n",
    "\n",
    "            except (ValueError, Exception) as e:\n",
    "                print(e)\n",
    "                print(\"请重新上传文件。\")\n",
    "\n",
    "        return mod_file\n",
    "\n",
    "def use_mod():\n",
    "    df = pd.read_excel(mod_file)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        file_type = row['类型']\n",
    "        file_name = row['名称']\n",
    "        download_link = row['下载地址']\n",
    "\n",
    "        if file_type == 'CKPT':\n",
    "            !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {download_link} -d {ckpt_dir} -o {file_name}\n",
    "        elif file_type == 'Lora':\n",
    "            !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {download_link} -d {lora_dir} -o {file_name}\n",
    "        elif file_type == 'VAE':\n",
    "            !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {download_link} -d {vae_dir} -o {file_name}\n",
    "        elif file_type == 'Extensions':\n",
    "            repo_name = download_link.split('/')[-1]\n",
    "            !git clone {download_link} {webui_dir}/extensions/{repo_name}\n",
    "        elif file_type == 'Embeddings':\n",
    "            !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {download_link} -d {embeddings_dir} -o {file_name}\n",
    "        elif file_type == 'Scripts':\n",
    "            !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {download_link} -d {webui_dir}/scripts -o {file_name}\n",
    "        elif file_type == 'Controlnet':\n",
    "            !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {download_link} -d {cn_dir} -o {file_name}\n",
    "        elif file_type == 'Comfyui_Nodes':\n",
    "            nodes_name = download_link.split('/')[-1]\n",
    "            !git clone {download_link} {webui_dir}/extensions/{nodes_name}\n",
    "\n",
    "if enable_mod:\n",
    "    mod_file = get_mod()\n",
    "    if mod_file:\n",
    "        use_mod()\n",
    "\n",
    "#@markdown---\n",
    "#@markdown ####<font color=\"#2b73af\"> 🌐☑使用云盘模型；☐不使用云盘模型。\n",
    "use_drive_model = False  #@param {type:\"boolean\"}\n",
    "#@markdown #####<font color=\"#2b73af\"> 两种方法：cp（从云盘复制到colab）；ln（添加云盘软链接到colab）\n",
    "content_way = \"\\u94FE\\u63A5ln\" #@param [\"\\u590D\\u5236cp\", \"\\u94FE\\u63A5ln\"]\n",
    "if use_drive and use_drive_model:\n",
    "    gckpt_dir = f\"/content/drive/MyDrive/{sd_name}/models/checkpoints\"\n",
    "    gLora_dir = f\"/content/drive/MyDrive/{sd_name}/models/Loras\"\n",
    "    gVAE_dir = f\"/content/drive/MyDrive/{sd_name}/models/vae\"\n",
    "    gembeddings_dir = f\"/content/drive/MyDrive/{sd_name}/embeddings\"\n",
    "    gcn_dir = f\"/content/drive/MyDrive/{sd_name}/extensions/models/controlnet\"\n",
    "    goutputs_dir = f\"/content/drive/MyDrive/{sd_name}/outputs\"\n",
    "    !mkdir -p {gLora_dir} {gVAE_dir} {gembeddings_dir} {gcn_dir} {goutputs_dir} {gckpt_dir}\n",
    "\n",
    "    if content_way == \"\\u590D\\u5236cp\":\n",
    "        !cp -r {gckpt_dir} {ckpt_dir}\n",
    "        !cp -r {gLora_dir} {Lora_dir}\n",
    "        !cp -r {gVAE_dir} {VAE_dir}\n",
    "        !cp -r {gembeddings_dir} {embeddings_dir}\n",
    "        !cp -r {gcn_dir} {cn_dir}\n",
    "    else:\n",
    "        !ln -sf {gckpt_dir} {ckpt_dir}\n",
    "        !ln -sf {gLora_dir} {Lora_dir}\n",
    "        !ln -sf {gVAE_dir} {VAE_dir}\n",
    "        !ln -sf {gembeddings_dir} {embeddings_dir}\n",
    "        !ln -sf {gcn_dir} {cn_dir}\n",
    "\n",
    "#@markdown---\n",
    "#@markdown ##<font color=\"#11659a\">▶️ Start Fooocus\n",
    "%cd {webui_dir}\n",
    "!python launch.py --share\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
